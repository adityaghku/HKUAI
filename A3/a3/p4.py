import sys, math, random, timefrom p1 import deepcopyfrom p2 import initialiseVGridfrom p3 import movePlayerP3, outputPolicy, initialisePolicy# We use the same parsing function defined in parser.py for problem 3from parse import read_grid_mdp_problem_p3"""How to run the file: python p4.py [FILE PATH TO PROBLEM] [DESIRED NUMBER OF ITERATIONS]Example: python p4.py test_cases/p3/2.prob 100 (in the assignment folder) will run the program 100 times and print out the number of succesful resultsInput: The same parsing function from p3 has been used, and the variable iterations has just been ignoredI could change the input etc and make custom files, but since its one test case and its quite trivialto change the input, i just left it as the same as p3. You can just use any txt file to inputwith the same format as p3 to get the input for p4. Output:For every iteration, the V_k and pi_k will be printed as in p3. At the end, it will also sayFinal Policy in x iterations, and whether the result after convergence was successful. At the end of all the iterations, it will show the success rate. I received 95 / 100 with the currentparameters (more on that later). It will also print the time taken (around 5 seconds in my case)Parameters:I picked alpha = 0.1 and epsilon = 0.01. reducing randomness helps the policy converge much quicker, but doesn'treally affect the success rate. A too high Alpha slows down the program by a lot and also massivelyaffects the success rate in some cases. For the convergence criteria, I kept k=10 as a minimum, and I checked whether the V values converge on successive iterations. If all their differences are < 1e-3,then we say they converge. Choosing a more stringent convergence criteria puts the program in an infinite loop, probably due to rounding errors etc.  s"""def diffArray(array1, array2):    temp = []    for i in range(len(array1)):        temp2 = []        for j in range(len(array1[i])):            if array1[i][j] == "#####":                temp2.append("#####")            else:                temp2.append(abs(array1[i][j] - array2[i][j]))        temp.append(temp2)    return tempdef hasConverged(dArray):    for i in range(len(dArray)):        for j in range(len(dArray[i])):            if dArray[i][j] != "#####":                if dArray[i][j] > 1e-3:                    return False    return Truedef outputVGrid(policy):    temp = ""    for i in range(len(policy)):        for j in range(len(policy[i])):            if policy[i][j] == "#####":                temp += "|{:^7}|".format(policy[i][j])            else:                temp += "|{:7.5f}|".format(policy[i][j])        temp += "\n"    return tempdef VScore(grid, intendedMove, i, j, vGrid, vGridArray):    tempVValue = 0    for move in d[intendedMove]:        if move == intendedMove:            _, newPos, _ = movePlayerP3(deepcopy(grid), move, [i, j].copy())            if grid[newPos[0]][newPos[1]] in ["_", "S"]:                tempVValue += (1 - noise * 2) * (                    0 + vGridArray[newPos[0]][newPos[1]]                )            else:                tempVValue += (1 - noise * 2) * (                    float(grid[newPos[0]][newPos[1]]) + 0                )        else:            _, newPos, _ = movePlayerP3(deepcopy(grid), move, [i, j].copy())            if grid[newPos[0]][newPos[1]] in ["_", "S"]:                tempVValue += noise * (0 + vGridArray[newPos[0]][newPos[1]])            else:                tempVValue += noise * (float(grid[newPos[0]][newPos[1]]) + 0)    return (discount * tempVValue) + livingRewarddef temporal_learning(problem):    global noise, discount, livingReward, d, moves    discount, noise, livingReward, iterations, grid = problem    noise = float(noise)    discount = float(discount)    livingReward = float(livingReward)    alpha = 0.1    eps = 0.01    d = {        "N": ["N", "E", "W"],        "E": ["E", "S", "N"],        "S": ["S", "W", "E"],        "W": ["W", "N", "S"],    }    moves = ["N", "E", "S", "W"]    vGrid = initialiseVGrid(grid)    vGridArray = [deepcopy(vGrid)]    vGridArray.append(deepcopy(vGrid))    k = 0    ans = "V_k=" + str(k) + "\n"    ans += outputVGrid(vGrid)    policy = initialisePolicy(grid)    for i in range(len(grid)):        for j in range(len(grid[i])):            if grid[i][j] not in ["#"]:                if grid[i][j] not in ["_", "S"]:                    vGrid[i][j] = float(grid[i][j])                else:                    vGrid[i][j] += livingReward    k += 1    ans += "V_k=" + str(k) + "\n"    ans += outputVGrid(vGrid)    ans += "pi_k=" + str(k) + "\n"    ans += outputPolicy(policy)    while k < 10 or not hasConverged(diffArray(vGridArray[-1], vGridArray[-2])):        vGridArray.append(deepcopy(vGrid))        for i in range(len(policy)):            for j in range(len(policy[i])):                if grid[i][j] not in ["_", "S", "#"]:                    vGrid[i][j] = float(grid[i][j])                else:                    if policy[i][j] not in ["#"]:                        if random.uniform(0, 1) < eps:                            maxMove = random.choice(moves)                            maxScore = VScore(                                grid,                                maxMove,                                i,                                j,                                deepcopy(vGrid),                                deepcopy(vGridArray[-1]),                            )                        else:                            maxScore = -math.inf                            maxMove = ""                            for move in moves:                                tempScore = VScore(                                    grid,                                    move,                                    i,                                    j,                                    deepcopy(vGrid),                                    deepcopy(vGridArray[-1]),                                )                                # deal with rounding error                                if tempScore > maxScore and (                                    abs(tempScore - maxScore) > 1e-5                                ):                                    maxScore = tempScore                                    maxMove = move                        vGrid[i][j] = (1 - alpha) * vGrid[i][                            j                        ] + alpha * discount * maxScore                        if grid[i][j] in ["_", "S"]:                            policy[i][j] = maxMove        k += 1        ans += "V_k=" + str(k) + "\n"        ans += outputVGrid(vGrid)        ans += "pi_k=" + str(k) + "\n"        ans += outputPolicy(policy)    return ans[:-1], policy, kdef main(file_path):    # file_path = "test_cases/p3/2.prob"    problem = read_grid_mdp_problem_p3(file_path)    ans, finalPolicy, k = temporal_learning(problem)    print(ans)    print("Final Policy in", k, "iterations")    print(outputPolicy(finalPolicy)[:-1])    if (        outputPolicy(finalPolicy)        == """| E || E || E || x |\n| N || # || W || x |\n| N || W || W || S |\n"""    ):        print("Successful convergence")        return 1    else:        print("Failed convergence")        return 0if __name__ == "__main__":    start_time = time.time()    results = 0    file_path = sys.argv[1]    iterations = int(sys.argv[2])    for i in range(iterations):        results += main(file_path)    print("Success Rate", results, "/", iterations)    print("Program took %s seconds" % (time.time() - start_time))